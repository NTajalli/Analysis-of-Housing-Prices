{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d786c79-c179-418e-bb2e-723b6df674c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af7e8c-8cd7-43be-b356-ae5c3ad94a38",
   "metadata": {},
   "source": [
    "<font size=\"8\" color=\"Black\">Part 1 and 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa412d2-2162-43cc-9ce0-5a8486b85aa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Metro_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract data of housing price average f| 5 most populated cities in US\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#pd.set_option('display.max_rows', 500)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m prices \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMetro_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m prices \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmelt(prices, id_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegionName\u001b[39m\u001b[38;5;124m'\u001b[39m], value_vars\u001b[38;5;241m=\u001b[39mprices\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m5\u001b[39m:])\n\u001b[1;32m      5\u001b[0m prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Metro_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'"
     ]
    }
   ],
   "source": [
    "# Extract data of housing price average f| 5 most populated cities in US\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "prices = pd.read_csv('Metro_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv').head(6).tail(-1)\n",
    "prices = pd.melt(prices, id_vars=['RegionName'], value_vars=prices.columns[5:])\n",
    "prices['Date'] = pd.to_datetime(prices['variable'])\n",
    "prices['Date'] = prices['Date'].astype('str')\n",
    "prices = prices.drop('variable', axis=1).rename(columns={'value': 'Average Price'})\n",
    "prices['Date'] = pd.DatetimeIndex(prices['Date'])\n",
    "prices['Year'] = pd.DatetimeIndex(prices['Date']).year\n",
    "prices.drop(columns='Date', axis=1)\n",
    "display(prices)\n",
    "prices = prices.groupby(['Year', 'RegionName']).aggregate(np.mean)\n",
    "prices = prices.reset_index()\n",
    "# Plot the avergae house price per month for each city\n",
    "fig, ax = plt.subplots()\n",
    "prices = prices.rename(columns={'RegionName': 'City'})\n",
    "prices.groupby('City')['Average Price'].plot(x='Year', y='Average Price', figsize=(30, 15), ax=ax)\n",
    "plt.legend(prop={'size': 15})\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.show()\n",
    "prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e4ce42-4178-4c68-94d1-65081e75dd6a",
   "metadata": {},
   "source": [
    "This is our code to gather data on the median house price for each of our 5 cities since 2000. All it is is a bunch\n",
    "of data tidying to organize our table into a readable format. We have also included a graph that shows how each city's\n",
    "median house price has changed based on the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cee7a1-6f31-40d5-b73f-36b3607f4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function drops rows that combine multiple cities (which makes no sense) after melting\n",
    "def drop_invalid(df):\n",
    "    cities = [] \n",
    "    for index, row in df.iterrows():\n",
    "        if ('New York' in row['variable'] and row['City'] == 'New York, NY'):\n",
    "            cities.append('New York, NY')\n",
    "        elif ('Los Angeles' in row['variable'] and row['City'] == 'Los Angeles, CA'):\n",
    "            cities.append('Los Angeles, CA')\n",
    "        elif ('Chicago' in row['variable'] and row['City'] == 'Chicago, IL'):\n",
    "            cities.append('Chicago, IL')\n",
    "        elif ('Houston' in row['variable'] and row['City'] == 'Houston, TX'):\n",
    "            cities.append('Houston, TX')\n",
    "        elif ('Dallas' in row['variable'] and row['City'] == 'Dallas, TX'):\n",
    "            cities.append('Dallas, TX')\n",
    "        else:\n",
    "            df = df.drop(index)\n",
    "     \n",
    "    df['City'] = cities      \n",
    "    return df.drop('variable',axis=1)\n",
    "\n",
    "\n",
    "# Read the data \n",
    "df = pd.read_csv('demographics.csv')\n",
    "df['Year'] = pd.DatetimeIndex(df['date']).year\n",
    "# Get recent data \n",
    "df = df[(df['Year'] > 2011)] \n",
    "df = df.drop('date', axis=1)\n",
    "\n",
    "# DATA TIDYING. VERY MESSY, LOTS OF MELTING, BUT NECESSARY\n",
    "df2 = df.head(10)\n",
    "df = df.tail(-10)\n",
    "df = df.groupby('Year').aggregate(np.mean)\n",
    "df = df.fillna(df2.set_index('Year')).reset_index()\n",
    "            \n",
    "df = pd.melt(df, id_vars=['Year',\n",
    "       'Los Angeles Count_Person_EducationalAttainmentBachelorsDegreeOrHigher',\n",
    "       'Los Angeles Count_Person',\n",
    "       'Chicago Count_Person_EducationalAttainmentBachelorsDegreeOrHigher',\n",
    "       'Chicago Count_Person',\n",
    "       'New York City Count_Person_EducationalAttainmentBachelorsDegreeOrHigher',\n",
    "       'New York City Count_Person',\n",
    "       'Dallas Count_Person_EducationalAttainmentBachelorsDegreeOrHigher',\n",
    "       'Dallas Count_Person',\n",
    "       'Houston Count_Person_EducationalAttainmentBachelorsDegreeOrHigher',\n",
    "       'Houston Count_Person', 'Los Angeles UnemploymentRate_Person',\n",
    "       'Chicago UnemploymentRate_Person',\n",
    "       'New York City UnemploymentRate_Person',\n",
    "       'Dallas UnemploymentRate_Person', 'Houston UnemploymentRate_Person',\n",
    "       'Los Angeles Median_Income_Household',\n",
    "       'Chicago Median_Income_Household',\n",
    "       'New York City Median_Income_Household',\n",
    "       'Dallas Median_Income_Household', 'Houston Median_Income_Household'], value_name='Population under poverty line', \n",
    "             value_vars=['Los Angeles Count_Person_BelowPovertyLevelInThePast12Months', 'Chicago Count_Person_BelowPovertyLevelInThePast12Months',\n",
    "             'New York City Count_Person_BelowPovertyLevelInThePast12Months',\n",
    "            'Houston Count_Person_BelowPovertyLevelInThePast12Months',\n",
    "            'Dallas Count_Person_BelowPovertyLevelInThePast12Months'])  \n",
    "\n",
    "cities = [] \n",
    "for index, row in df.iterrows():\n",
    "    if ('New York City' in row['variable']):\n",
    "        cities.append('New York, NY')\n",
    "    elif ('Los Angeles' in row['variable']):\n",
    "        cities.append('Los Angeles, CA')\n",
    "    elif ('Chicago' in row['variable']):\n",
    "        cities.append('Chicago, IL')\n",
    "    elif ('Houston' in row['variable']):\n",
    "        cities.append('Houston, TX')\n",
    "    else:\n",
    "        cities.append('Dallas, TX')\n",
    "     \n",
    "df['City'] = cities      \n",
    "df = df.drop('variable',axis=1)\n",
    "\n",
    "df = pd.melt(df, id_vars=['Year', 'Population under poverty line', 'Los Angeles Count_Person', 'City',\n",
    "                        'Chicago Count_Person',\n",
    "                        'New York City Count_Person',\n",
    "                        'Dallas Count_Person',\n",
    "                        'Houston Count_Person', 'Los Angeles UnemploymentRate_Person',\n",
    "                        'Chicago UnemploymentRate_Person',\n",
    "                        'New York City UnemploymentRate_Person',\n",
    "                        'Dallas UnemploymentRate_Person', 'Houston UnemploymentRate_Person',\n",
    "                        'Los Angeles Median_Income_Household',\n",
    "                        'Chicago Median_Income_Household',\n",
    "                        'New York City Median_Income_Household',\n",
    "                        'Dallas Median_Income_Household', 'Houston Median_Income_Household'], value_name='Population with Bachelors or Higher',       \n",
    "             value_vars=['Los Angeles Count_Person_EducationalAttainmentBachelorsDegreeOrHigher',         \n",
    "                        'Chicago Count_Person_EducationalAttainmentBachelorsDegreeOrHigher',\n",
    "                        'New York City Count_Person_EducationalAttainmentBachelorsDegreeOrHigher',\n",
    "                        'Dallas Count_Person_EducationalAttainmentBachelorsDegreeOrHigher',\n",
    "                        'Houston Count_Person_EducationalAttainmentBachelorsDegreeOrHigher'])\n",
    "\n",
    "df = drop_invalid(df)\n",
    "\n",
    "df = pd.melt(df, id_vars=['Year', 'Population under poverty line', 'Population with Bachelors or Higher', 'City',\n",
    "                            'Los Angeles UnemploymentRate_Person',\n",
    "                            'Chicago UnemploymentRate_Person',\n",
    "                            'New York City UnemploymentRate_Person',\n",
    "                            'Dallas UnemploymentRate_Person', 'Houston UnemploymentRate_Person',\n",
    "                            'Los Angeles Median_Income_Household',\n",
    "                            'Chicago Median_Income_Household',\n",
    "                            'New York City Median_Income_Household',\n",
    "                            'Dallas Median_Income_Household', 'Houston Median_Income_Household'], \n",
    "             value_name='Total Population', value_vars=['Los Angeles Count_Person',\n",
    "                                                        'Chicago Count_Person',\n",
    "                                                      'New York City Count_Person',\n",
    "                                                        'Dallas Count_Person',\n",
    "                                                        'Houston Count_Person'])\n",
    "df = drop_invalid(df)\n",
    "df = pd.melt(df, id_vars=['Year', 'Population under poverty line', 'Population with Bachelors or Higher', 'Total Population', 'City',\n",
    "                        'Los Angeles Median_Income_Household',\n",
    "                        'Chicago Median_Income_Household',\n",
    "                        'New York City Median_Income_Household',\n",
    "                        'Dallas Median_Income_Household', 'Houston Median_Income_Household'], \n",
    "             value_name='Unemployment Rate', value_vars=['Los Angeles UnemploymentRate_Person',\n",
    "                                                        'Chicago UnemploymentRate_Person',\n",
    "                                                        'New York City UnemploymentRate_Person',\n",
    "                                                        'Dallas UnemploymentRate_Person', 'Houston UnemploymentRate_Person'])\n",
    "df = drop_invalid(df)\n",
    "df = pd.melt(df, id_vars=['Year', 'City', 'Population under poverty line', 'Population with Bachelors or Higher', 'Total Population', 'Unemployment Rate'], \n",
    "             value_name='Median Household Income', value_vars=['Los Angeles Median_Income_Household',\n",
    "                                   'Chicago Median_Income_Household',\n",
    "                                   'New York City Median_Income_Household',\n",
    "                                   'Dallas Median_Income_Household', 'Houston Median_Income_Household'])\n",
    "df = drop_invalid(df)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if (pd.isna(row['Population with Bachelors or Higher']) or pd.isna(row['Total Population']) or pd.isna(row['Unemployment Rate']) or pd.isna(row['Median Household Income'])):\n",
    "        df = df.drop(index)\n",
    "df = df.reset_index().drop('index', axis=1)\n",
    "df['Percent of Population with Bachelors or Higher'] = 100 * df['Population with Bachelors or Higher'] / df['Total Population']\n",
    "df['Percent of Population Under Poverty Line'] = 100 * df['Population under poverty line'] / df['Total Population']\n",
    "df = df.drop('Population with Bachelors or Higher', axis=1).drop('Population under poverty line', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9bbb9b-037d-4269-9721-03c8130875b3",
   "metadata": {},
   "source": [
    "We gathered this data off using a census tool that allows us to combine data into tables, which is how we got the csv.\n",
    "Although we initially had all the data in the table, it was unusable. In order to make it usable and readable, we had to\n",
    "melt it a good amount as you can see above. Although it was messy, we were able to tidy the data into one nice table that shows\n",
    "demographics data on the cities from 2012-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f1866-17ff-4e6b-9b8b-85ea734c733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.merge(prices, on=[\"City\", \"Year\"])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8f6626-a341-47bd-b466-81a6605218dd",
   "metadata": {},
   "source": [
    "Now, all we got to do is merge the two tables into one table with all our data for each year. This is what we will use \n",
    "for the future parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fbdf12-c3f7-4b1e-aa7e-92121b04b837",
   "metadata": {},
   "source": [
    "<font size=\"8\" color=\"Black\">Part 3</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639ca0d",
   "metadata": {},
   "source": [
    "After finishing the table, lets analyze some information in the table that might impact the price of the house in \n",
    "different cities. First, we want to do so visually by plotting out each factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7119409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a line plot of Average Price From 2012-2020\n",
    "city_set = set(final_df['City'])\n",
    "\n",
    "plt.figure(figsize=(30,15)) \n",
    "for city in city_set:\n",
    "     selected_data = final_df.loc[final_df['City'] == city]\n",
    "     plt.plot(selected_data['Year'], selected_data['Average Price'], label=city)\n",
    "    \n",
    "plt.title(\"Average Price From 2012-2020\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7436e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a line plot of Total Population From 2012-2020\n",
    "city_set = set(final_df['City'])\n",
    "\n",
    "plt.figure(figsize=(30,15)) \n",
    "for city in city_set:\n",
    "     selected_data = final_df.loc[final_df['City'] == city]\n",
    "     plt.plot(selected_data['Year'], selected_data['Total Population'], label=city)\n",
    "    \n",
    "plt.title(\"Total Population From 2012-2020\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Total Population (million people)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a line plot of Unemployment Rate From 2012-2020\n",
    "city_set = set(final_df['City'])\n",
    "\n",
    "plt.figure(figsize=(30,15)) \n",
    "for city in city_set:\n",
    "     selected_data = final_df.loc[final_df['City'] == city]\n",
    "     plt.plot(selected_data['Year'], selected_data['Unemployment Rate'], label=city)\n",
    "    \n",
    "plt.title(\"Unemployment Rate From 2012-2020\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Unemployment Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b54291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a line plot of Median Household Income From 2012-2020\n",
    "city_set = set(final_df['City'])\n",
    "\n",
    "plt.figure(figsize=(30,15)) \n",
    "for city in city_set:\n",
    "     selected_data = final_df.loc[final_df['City'] == city]\n",
    "     plt.plot(selected_data['Year'], selected_data['Median Household Income'], label=city)\n",
    "    \n",
    "plt.title(\"Median Household Income From 2012-2020\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Median Household Income\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a line plot of Percent of Population with Bachelors or Higher From 2012-2020\n",
    "city_set = set(final_df['City'])\n",
    "\n",
    "plt.figure(figsize=(30,15)) \n",
    "for city in city_set:\n",
    "     selected_data = final_df.loc[final_df['City'] == city]\n",
    "     plt.plot(selected_data['Year'], selected_data['Percent of Population with Bachelors or Higher'], label=city)\n",
    "    \n",
    "plt.title(\"Percent of Population with Bachelors or Higher From 2012-2020\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Percent of Population with Bachelors or Higher\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a line plot of Percent of Population Under Poverty Line From 2012-2020\n",
    "city_set = set(final_df['City'])\n",
    "\n",
    "plt.figure(figsize=(30,15)) \n",
    "for city in city_set:\n",
    "     selected_data = final_df.loc[final_df['City'] == city]\n",
    "     plt.plot(selected_data['Year'], selected_data['Percent of Population Under Poverty Line'], label=city)\n",
    "    \n",
    "plt.title(\"Percent of Population Under Poverty Line From 2012-2020\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Percent of Population Under Poverty Line\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394cec43",
   "metadata": {},
   "source": [
    "From the graph above, we can know that the average price has been increasing from 2012-2020. Total Population \n",
    "doesn't change too much. Unemployment rate decerased and increased. Median household Income and Percent of Population with Bachelors increases consistently; Percent of Population Under Poverty Line decreases consistently from 2012-2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1f1c7",
   "metadata": {},
   "source": [
    "Since the average house price has a trend that is increasing constantly, we want to find out that what might be the reasons leads to the increaing price. So we are going to draw a correlation matrix to find out the relationships between those factors and average house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fe455",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "correlation_matrix = final_df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088a2d0",
   "metadata": {},
   "source": [
    "The correlation matrix shows us that there are 4 factors that might be able to impact the housing price. Those are:Year, Totoal Population, Median Household Income, Percent of Population with Bachelors or Higher, Percent of population Under Proverty. In these factor, Median Household Income has a strong relationship with Average price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fbe582-83f2-4acd-afbf-218c24f1c4cd",
   "metadata": {},
   "source": [
    "<font size=\"8\" color=\"Black\">Part 4</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b400247",
   "metadata": {},
   "source": [
    "We are going to build an initial regression model to predict the house price between differnet cities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ec109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for the categorical variable 'City'\n",
    "le = LabelEncoder()\n",
    "final_df['City'] = le.fit_transform(final_df['City'])\n",
    "\n",
    "# Defining predictors and target variable\n",
    "X = final_df[['City', 'total_population', 'median_household_income', 'percent_bachelors_or_higher', \n",
    "        'unemployment_rate', 'percent_under_poverty_line', 'Year']]\n",
    "y = final_df['average_price']\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", mse**(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8ae92",
   "metadata": {},
   "source": [
    "The Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) are both measures of model accuracy, with lower values indicating better performance.\n",
    "\n",
    "The model's MSE is 2861185276.97, and the RMSE is 53490.05. The RMSE can be interpreted in the same units as the dependent variable, which in this case is the average house price. This means that, on average, your model's predictions are approximately $53,490 off from the actual house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c542169",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_predicted_price = np.mean(y_pred)\n",
    "print(\"The average predicted house price is: \", average_predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a new data point for the new city\n",
    "new_city_data = {'City': [4], 'total_population': [8433867], 'median_household_income': [63998], \n",
    "                 'percent_bachelors_or_higher': [0.27351827], 'unemployment_rate': [0.441667], \n",
    "                 'percent_under_poverty_line': [0.17116053], 'Year': [2023]}\n",
    "\n",
    "new_df = pd.DataFrame(new_city_data)\n",
    "\n",
    "# Convert all 'City' values in the original dataframe to strings and perform label encoding\n",
    "final_df['City'] = final_df['City'].astype(str)\n",
    "le = LabelEncoder()\n",
    "final_df['City'] = le.fit_transform(final_df['City'])\n",
    "\n",
    "# Separate predictors and target variable for the original data and train the model\n",
    "X = final_df[['City', 'total_population', 'median_household_income', 'percent_bachelors_or_higher', \n",
    "        'unemployment_rate', 'percent_under_poverty_line', 'Year']]\n",
    "y = final_df['average_price']\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Convert 'City' in new data to string, encode it and make a prediction\n",
    "new_df['City'] = new_df['City'].astype(str)\n",
    "new_city_encoded = le.transform(new_df['City'])\n",
    "new_df['City'] = new_city_encoded\n",
    "\n",
    "# Now you can predict the house price for the new city\n",
    "new_city_prediction = model.predict(new_df)\n",
    "\n",
    "# Print out the prediction\n",
    "print(\"Predicted average house price for the new city: \", new_city_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87188bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f0150",
   "metadata": {},
   "source": [
    "Let's try some tactics that might be able to improve the accruary of the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['income_per_population'] = final_df['median_household_income'] / final_df['total_population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c28561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to add the new feature to the new city data as well\n",
    "new_df['income_per_population'] = new_df['median_household_income'] / new_df['total_population']\n",
    "\n",
    "# Redefine your feature set to include the new feature\n",
    "X = final_df[['City', 'total_population', 'median_household_income', 'percent_bachelors_or_higher', 'unemployment_rate', 'percent_under_poverty_line', 'Year', 'income_per_population']]\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Now you can predict the house price for the new city using the updated model\n",
    "new_city_prediction = model.predict(new_df)\n",
    "\n",
    "# Print out the prediction\n",
    "print(\"Predicted average house price for the new city: \", new_city_prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa31dabd-3a09-4030-b7b3-82067cc9b4e4",
   "metadata": {},
   "source": [
    "<font size=\"8\" color=\"Black\">Part 5</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773aef65-1744-4aa6-afb4-67577215a367",
   "metadata": {},
   "source": [
    "<font size=\"8\" color=\"Black\">Part 6</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d96050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f0f44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3fa918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
